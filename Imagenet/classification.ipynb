{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras,os,wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"image-net-classification-myLaptop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take Dataset from Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "    \n",
    "    return tf.cast(image, tf.float32) / 255.0, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 files belonging to 200 classes.\n",
      "Found 10000 files belonging to 200 classes.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "train_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory=\"dataset\\\\train\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size = (64,64),\n",
    "    shuffle=True,\n",
    "    )\n",
    "val_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory=\"dataset\\\\val\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size = (64,64),\n",
    "    shuffle=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_ds = train_ds.map(normalize_img,num_parallel_calls=AUTOTUNE).cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.map(normalize_img,num_parallel_calls=AUTOTUNE).cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(64, 64, 3), dtype=float32, numpy=\n",
       " array([[[0.50980395, 0.49803922, 0.47058824],\n",
       "         [0.6666667 , 0.654902  , 0.627451  ],\n",
       "         [0.6431373 , 0.6313726 , 0.6039216 ],\n",
       "         ...,\n",
       "         [0.40392157, 0.39607844, 0.4       ],\n",
       "         [0.29803923, 0.2901961 , 0.29411766],\n",
       "         [0.7490196 , 0.7411765 , 0.74509805]],\n",
       " \n",
       "        [[0.5686275 , 0.5568628 , 0.5294118 ],\n",
       "         [0.59607846, 0.58431375, 0.5568628 ],\n",
       "         [0.54901963, 0.5372549 , 0.50980395],\n",
       "         ...,\n",
       "         [0.6039216 , 0.59607846, 0.6       ],\n",
       "         [0.7058824 , 0.69803923, 0.7019608 ],\n",
       "         [0.78039217, 0.77254903, 0.7764706 ]],\n",
       " \n",
       "        [[0.59607846, 0.5921569 , 0.57254905],\n",
       "         [0.6       , 0.59607846, 0.5764706 ],\n",
       "         [0.6       , 0.59607846, 0.5764706 ],\n",
       "         ...,\n",
       "         [0.78431374, 0.7764706 , 0.78039217],\n",
       "         [0.8       , 0.7921569 , 0.79607844],\n",
       "         [0.7019608 , 0.69411767, 0.69803923]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.50980395, 0.49019608, 0.47843137],\n",
       "         [0.53333336, 0.5137255 , 0.5019608 ],\n",
       "         [0.5058824 , 0.4862745 , 0.47058824],\n",
       "         ...,\n",
       "         [0.5294118 , 0.39607844, 0.36078432],\n",
       "         [0.62352943, 0.49019608, 0.45490196],\n",
       "         [0.4627451 , 0.31764707, 0.29411766]],\n",
       " \n",
       "        [[0.47843137, 0.45882353, 0.44313726],\n",
       "         [0.4       , 0.38039216, 0.3647059 ],\n",
       "         [0.42352942, 0.40392157, 0.3882353 ],\n",
       "         ...,\n",
       "         [0.5568628 , 0.4117647 , 0.3764706 ],\n",
       "         [0.6039216 , 0.4509804 , 0.42352942],\n",
       "         [0.5058824 , 0.3529412 , 0.3254902 ]],\n",
       " \n",
       "        [[0.42352942, 0.40392157, 0.3882353 ],\n",
       "         [0.31764707, 0.29803923, 0.28235295],\n",
       "         [0.38431373, 0.3647059 , 0.34901962],\n",
       "         ...,\n",
       "         [0.7490196 , 0.60784316, 0.56078434],\n",
       "         [0.56078434, 0.4       , 0.3764706 ],\n",
       "         [0.70980394, 0.54901963, 0.5254902 ]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=175>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_batch, label_batch = next(iter(train_ds))\n",
    "image_batch[0],label_batch[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Layer,Conv2D,Dense,BatchNormalization,MaxPooling2D,GlobalAveragePooling2D,Dropout\n",
    "from keras import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import SparseCategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCNNBlock(Layer):\n",
    "\n",
    "    def __init__(self,output_channels,kernel_size=3,pool_size=3):\n",
    "\n",
    "        super(myCNNBlock, self).__init__()\n",
    "\n",
    "        \n",
    "\n",
    "        self.conv = Conv2D(output_channels,kernel_size=kernel_size,padding=\"same\")\n",
    "        self.pooling = MaxPooling2D(pool_size=pool_size)\n",
    "        self.bn = BatchNormalization()\n",
    "\n",
    "    def call(self,input_tensor,training=False):\n",
    "\n",
    "        x = self.conv(input_tensor)\n",
    "        x = self.bn(x,training=training)\n",
    "        #x = self.pooling(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        return x\n",
    "\n",
    "class myCNN(Layer):\n",
    "\n",
    "    def __init__(self,channels):\n",
    "\n",
    "        super(myCNN, self).__init__()\n",
    "   \n",
    "        self.cnn1 = myCNNBlock(output_channels=channels[0])\n",
    "        self.cnn2 = myCNNBlock(output_channels=channels[1])\n",
    "        self.cnn3 = myCNNBlock(output_channels=channels[2])\n",
    "        \n",
    "        self.maxPool = MaxPooling2D()\n",
    "        self.identity_mapping = Conv2D(channels[1],3,padding=\"same\")\n",
    "    \n",
    "    \n",
    "\n",
    "    def call(self,input_tensor,training=False):\n",
    "\n",
    "        x = self.cnn1(input_tensor,training=training)\n",
    "        x = self.cnn2(x,training=training)\n",
    "        x = self.cnn3(x + self.identity_mapping(input_tensor),training=training)\n",
    "      \n",
    "        x = self.maxPool(x)\n",
    "       \n",
    "\n",
    "        return x\n",
    "\n",
    "class fullModel(Model):\n",
    "\n",
    "    def __init__(self,number_of_classes=200,):\n",
    "\n",
    "        super(fullModel,self).__init__(name=\"fullModel\")\n",
    "\n",
    "        self.lightM1 = myCNN([32,32,64])\n",
    "        self.lightM2 = myCNN([64,64,128])\n",
    "        self.lightM3 = myCNN([128,256,512])\n",
    "        self.lightM4 = myCNN([256,512,1024])\n",
    "\n",
    "        self.pool = GlobalAveragePooling2D()\n",
    "        self.dropout = Dropout(0.5)\n",
    "        self.dense1 = Dense(512)\n",
    "        \n",
    "       \n",
    "        self.classifier = Dense(number_of_classes)\n",
    "\n",
    "    def call(self,input_tensor,training=False):\n",
    "\n",
    "        x = self.lightM1(input_tensor,training=training)\n",
    "        x = self.lightM2(x,training=training)\n",
    "        x = self.lightM3(x,training=training)\n",
    "        x = self.lightM4(x,training=training)\n",
    "        x = self.pool(x)\n",
    "        x = self.dense1(x)\n",
    "        #x = self.dropout(x)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x \n",
    "    \n",
    "    def model(self,):\n",
    "        x = keras.Input(shape = (64,64,3))\n",
    "\n",
    "        return Model(inputs=[x],outputs = self.call(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fullModel().model()\n",
    "\n",
    "model.compile(optimizer = Adam(learning_rate=0.0001),loss=SparseCategoricalCrossentropy(from_logits=True),metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " my_cnn (myCNN)              (None, 32, 32, 64)        30048     \n",
      "                                                                 \n",
      " my_cnn_1 (myCNN)            (None, 16, 16, 128)       185664    \n",
      "                                                                 \n",
      " my_cnn_2 (myCNN)            (None, 8, 8, 512)         1921664   \n",
      "                                                                 \n",
      " my_cnn_3 (myCNN)            (None, 4, 4, 1024)        9446656   \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1024)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               102600    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,211,432\n",
      "Trainable params: 12,205,288\n",
      "Non-trainable params: 6,144\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"model/weights-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy',save_weights_only=True, save_best_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights(\"model\\weights-14-0.17.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_ds,validation_data=val_ds,epochs=200,callbacks=[checkpoint],verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCNNBlock(Layer):\n",
    "\n",
    "    def __init__(self,output_channels,pool_size=3,kernel_size=3,):\n",
    "        super(myCNNBlock,self).__init__()\n",
    "\n",
    "        self.conv = Conv2D(output_channels,kernel_size=kernel_size,padding=\"same\")\n",
    "        self.maxPool = MaxPooling2D(pool_size=pool_size)\n",
    "        self.batch = BatchNormalization()\n",
    "        \n",
    "    \n",
    "    def call(self,input_tensor,training=False):\n",
    "\n",
    "        x = self.conv(input_tensor)\n",
    "        x = self.batch(x,training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        #x = self.maxPool(x)\n",
    "       \n",
    "        return x\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myResBlock(Layer):\n",
    "\n",
    "    def __init__(self,channels):\n",
    "        super(myResBlock,self).__init__()\n",
    "\n",
    "\n",
    "        self.cnn1 = myCNNBlock(channels[0],3)\n",
    "        self.cnn2 = myCNNBlock(channels[1],3)\n",
    "        self.cnn3 = myCNNBlock(channels[2],3)\n",
    "        \n",
    "        self.pooling = MaxPooling2D()\n",
    "        self.identity_mapping = Conv2D(channels[1],3,padding=\"same\")\n",
    "\n",
    "    def call(self,input_tensor,training=False):\n",
    "        \n",
    "        x = self.cnn1(input_tensor,training=training)\n",
    "        x = self.cnn2(x,training=training)\n",
    "        \n",
    "        x = self.cnn3(x + self.identity_mapping(input_tensor) ,training=training)\n",
    "        x = self.pooling(x)\n",
    "        \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(keras.Model):\n",
    "\n",
    "    def __init__(self,number_of_classes=10):\n",
    "        \n",
    "        super(ResNet,self).__init__()\n",
    "    \n",
    "        self.res1 = myResBlock([32,32,64])\n",
    "        self.res2 = myResBlock([128,128,256])\n",
    "        self.res3 = myResBlock([128,256,512])\n",
    "\n",
    "        self.pool = GlobalAveragePooling2D()\n",
    "        self.classifier = Dense(number_of_classes)\n",
    "    \n",
    "    def call(self,input_tensor,training=False):\n",
    "        #input_tensor = keras.Input(shape=input_tensor)\n",
    "        x = self.res1(input_tensor,training=training)\n",
    "        x = self.res2(x,training=training)\n",
    "        x = self.res3(x,training=training)\n",
    "        x = self.pool(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def model(self):\n",
    "        x = keras.Input(shape=(64,64,3))\n",
    "        return keras.Model(inputs=[x],outputs=self.call(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = ResNet().model()\n",
    "from keras.optimizers import Adam\n",
    "model2.compile(optimizer=Adam(learning_rate = 0.001),loss=SparseCategoricalCrossentropy(from_logits=True),metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.fit(train_ds,epochs=3,verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('machineLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ba0bac22d9eb68f7f5a06ef2e353ac664856aa0e4acc18841217d9d0b0f1928e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
